{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "from typing import Callable, Literal\n",
    "\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain_core.language_models.chat_models import BaseChatModel\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.tools.base import BaseTool\n",
    "from langgraph.checkpoint.memory import BaseCheckpointSaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.types import Command\n",
    "\n",
    "NodeType = Callable[[MessagesState], Command]\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(\n",
    "        self,\n",
    "        executor: AgentExecutor,\n",
    "        model: BaseChatModel,\n",
    "        memory: BaseCheckpointSaver,\n",
    "        tools: list[BaseTool],\n",
    "        verbose: bool = False,\n",
    "        config: dict[str, dict[str, str]] = {\"configurable\": {\"thread_id\": \"default\"}},\n",
    "    ):\n",
    "        self.executor = executor\n",
    "        self.model = model\n",
    "        self.memory = memory\n",
    "        self.verbose = verbose\n",
    "        self.tools = tools\n",
    "        self.config = config\n",
    "        self.graph = self.compile_graph()\n",
    "\n",
    "    def compile_graph(self) -> CompiledGraph:\n",
    "        g = StateGraph(MessagesState)\n",
    "        g.add_node(\"superagent\", self.create_super_node())\n",
    "        g.add_node(\"agent\", self.create_node())\n",
    "        g.add_edge(START, \"superagent\")\n",
    "        g.add_edge(\"superagent\", \"agent\")\n",
    "        return g.compile(checkpointer=self.memory)\n",
    "\n",
    "    def create_super_node(self) -> NodeType:\n",
    "        def superagent(state: MessagesState) -> Command[Literal[\"agent\", \"__end__\"]]:\n",
    "            system_prompt = textwrap.dedent(\n",
    "                f\"\"\"\n",
    "                Answer the following questions as best you can.\n",
    "                You have access to the following tools:\n",
    "                {self.tools}\n",
    "                \"\"\"\n",
    "            )\n",
    "            msgs = [SystemMessage(content=system_prompt), *state[\"messages\"]]\n",
    "            res = self.model.bind_tools(self.tools).invoke(msgs)\n",
    "            if len(res.tool_calls) > 0:\n",
    "                tool_call_id = res.tool_calls[-1][\"id\"]\n",
    "                tool_msg = {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": \"Successfully transferred\",\n",
    "                    \"tool_call_id\": tool_call_id,\n",
    "                }\n",
    "                return Command(goto=\"agent\", update={\"messages\": [res, tool_msg]})\n",
    "            else:\n",
    "                return Command(goto=\"__end__\", update={\"messages\": [res]})\n",
    "\n",
    "        return superagent\n",
    "\n",
    "    def create_node(self) -> NodeType:\n",
    "        def node(state: MessagesState):\n",
    "            res = self.executor.invoke({\"input\": state[\"messages\"]})\n",
    "            return {\"messages\": [res[\"output\"]]}\n",
    "\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_experiments.llm import create_model\n",
    "from llm_experiments import tools\n",
    "from langgraph.graph import MessagesState, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def create_agent():\n",
    "    def agent(state: MessagesState):\n",
    "        res = create_model().bind_tools(toolkit).invoke(state[\"messages\"])\n",
    "        return {\"messages\": [res]}\n",
    "\n",
    "    return agent\n",
    "\n",
    "\n",
    "def create_toolnode():\n",
    "    return ToolNode([tools.duckduckgo()])\n",
    "\n",
    "\n",
    "def create_should_continue():\n",
    "    def should_continue(state: MessagesState):\n",
    "        if state[\"messages\"][-1].tool_calls:\n",
    "            return \"tools\"\n",
    "        return END\n",
    "\n",
    "    return should_continue\n",
    "\n",
    "\n",
    "toolkit = [tools.duckduckgo()]\n",
    "g = StateGraph(MessagesState)\n",
    "g.add_node(\"agent\", create_agent())\n",
    "g.add_node(\"tools\", create_toolnode())\n",
    "g.add_edge(START, \"agent\")\n",
    "g.add_conditional_edges(\"agent\", create_should_continue(), [\"tools\", END])\n",
    "g.add_edge(\"tools\", \"agent\")\n",
    "app = g.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in app.stream({\"messages\": [\"search today's news\"]}, stream_mode=\"values\"):\n",
    "    print(i[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
